---
# CephFilesystem Custom Resource
# References the existing CephFS filesystem on the external cluster
apiVersion: ceph.rook.io/v1
kind: CephFilesystem
metadata:
  name: saasodoo-fs
  namespace: rook-ceph
spec:
  # Reference existing CephFS metadata pool
  # Pool name from: ceph fs ls
  metadataPool:
    # Don't create new pool - use existing
    # Pool: cephfs.saasodoo_fs.meta
    replicated:
      size: 3
      requireSafeReplicaSize: true
    parameters:
      compression_mode: none

  # Reference existing CephFS data pools
  dataPools:
    - name: cephfs.saasodoo_fs.data
      # Don't create new pool - use existing
      replicated:
        size: 3
        requireSafeReplicaSize: true
      parameters:
        compression_mode: none

  # Preserve filesystem on CephFilesystem deletion
  # CRITICAL: Set to true to prevent data loss
  preserveFilesystemOnDelete: true

  # Preserve pools on CephFilesystem deletion
  # CRITICAL: Set to true to prevent data loss
  preservePoolsOnDelete: true

  # Metadata server configuration
  # Note: External cluster already has MDS, this is for CSI only
  metadataServer:
    # Number of active MDS daemons
    activeCount: 1
    # Enable active-standby
    activeStandby: true
    # Resource limits for MDS pods (if Rook manages them)
    resources:
      limits:
        memory: "4Gi"
      requests:
        cpu: "1000m"
        memory: "2Gi"
    # Priority class
    priorityClassName: ""
    # Placement (optional)
    placement: {}
